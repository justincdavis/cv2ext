"""
This type stub file was generated by pyright.
"""

from functools import reduce
from contextlib import contextmanager
from numba.core import ir
from numba.core.typing.templates import AbstractTemplate, infer_global
from numba.core.extending import overload, register_jitable

"""
This module transforms data-parallel operations such as Numpy calls into
'Parfor' nodes, which are nested loops that can be parallelized.
It also implements optimizations such as loop fusion, and extends the rest of
compiler analysis and optimizations to support Parfors.
This is similar to ParallelAccelerator package in Julia:
https://github.com/IntelLabs/ParallelAccelerator.jl
'Parallelizing Julia with a Non-invasive DSL', T. Anderson et al., ECOOP'17.
"""
_termwidth = ...
_txtwrapper = ...
def print_wrapped(x): # -> None:
    ...

sequential_parfor_lowering = ...
def init_prange(): # -> None:
    ...

@overload(init_prange)
def init_prange_overload(): # -> Callable[[], None]:
    ...

class internal_prange:
    def __new__(cls, *args): # -> range:
        ...
    


def min_parallel_impl(return_type, arg): # -> Callable[..., Any]:
    ...

def max_parallel_impl(return_type, arg): # -> Callable[..., Any]:
    ...

def argmin_parallel_impl(in_arr):
    ...

def argmax_parallel_impl(in_arr):
    ...

def dotvv_parallel_impl(a, b): # -> Literal[0]:
    ...

def dotvm_parallel_impl(a, b): # -> NDArray[float64]:
    ...

def dotmv_parallel_impl(a, b): # -> NDArray[float64]:
    ...

def dot_parallel_impl(return_type, atyp, btyp): # -> Callable[..., Any | Literal[0]] | Callable[..., NDArray[float64]] | None:
    ...

def sum_parallel_impl(return_type, arg): # -> Callable[..., Any]:
    ...

def prod_parallel_impl(return_type, arg): # -> Callable[..., Any]:
    ...

def mean_parallel_impl(return_type, arg): # -> Callable[..., Any]:
    ...

def var_parallel_impl(return_type, arg): # -> Callable[..., Literal[0]]:
    ...

def std_parallel_impl(return_type, arg): # -> Callable[..., Any]:
    ...

def arange_parallel_impl(return_type, *args, dtype=...): # -> Callable[..., NDArray[bool_ | object_ | void]] | Callable[..., Any]:
    ...

def linspace_parallel_impl(return_type, *args): # -> Callable[..., Any] | Callable[..., NDArray[bool_ | object_ | void]]:
    ...

swap_functions_map = ...
def fill_parallel_impl(return_type, arr, val): # -> Callable[..., None]:
    """Parallel implementation of ndarray.fill.  The array on
       which to operate is retrieved from get_call_name and
       is passed along with the value to fill.
    """
    ...

replace_functions_ndarray = ...
@register_jitable
def max_checker(arr_size): # -> None:
    ...

@register_jitable
def min_checker(arr_size): # -> None:
    ...

@register_jitable
def argmin_checker(arr_size): # -> None:
    ...

@register_jitable
def argmax_checker(arr_size): # -> None:
    ...

checker_impl = ...
replace_functions_checkers_map = ...
class LoopNest:
    '''The LoopNest class holds information of a single loop including
    the index variable (of a non-negative integer value), and the
    range variable, e.g. range(r) is 0 to r-1 with step size 1.
    '''
    def __init__(self, index_variable, start, stop, step) -> None:
        ...
    
    def __repr__(self): # -> LiteralString:
        ...
    
    def list_vars(self): # -> list[Any]:
        ...
    


class Parfor(ir.Expr, ir.Stmt):
    id_counter = ...
    def __init__(self, loop_nests, init_block, loop_body, loc, index_var, equiv_set, pattern, flags, *, no_sequential_lowering=..., races=...) -> None:
        ...
    
    def __repr__(self): # -> str:
        ...
    
    def get_loop_nest_vars(self): # -> list[Any]:
        ...
    
    def list_vars(self): # -> list[Any]:
        """list variables used (read/written) in this parfor by
        traversing the body and combining block uses.
        """
        ...
    
    def get_shape_classes(self, var, typemap=...):
        """get the shape classes for a given variable.
        If a typemap is specified then use it for type resolution
        """
        ...
    
    def dump(self, file=...): # -> None:
        ...
    
    def validate_params(self, typemap): # -> None:
        """
        Check that Parfors params are of valid types.
        """
        ...
    


class ParforDiagnostics:
    """Holds parfor diagnostic info, this is accumulated throughout the
    PreParforPass and ParforPass, also in the closure inlining!
    """
    def __init__(self) -> None:
        ...
    
    def setup(self, func_ir, fusion_enabled): # -> None:
        ...
    
    @property
    def has_setup(self):
        ...
    
    @has_setup.setter
    def has_setup(self, state): # -> None:
        ...
    
    def count_parfors(self, blocks=...): # -> int:
        ...
    
    def get_parfors(self): # -> list[Any]:
        ...
    
    def hoisted_allocations(self): # -> list[Any]:
        ...
    
    def compute_graph_info(self, _a): # -> tuple[list[Any], set[Any]]:
        """
        compute adjacency list of the fused loops
        and find the roots in of the lists
        """
        ...
    
    def get_stats(self, fadj, nadj, root): # -> tuple[int | Any, Any]:
        """
        Computes the number of fused and serialized loops
        based on a fusion adjacency list `fadj` and a nested
        parfors adjacency list `nadj` for the root, `root`
        """
        ...
    
    def reachable_nodes(self, adj, root): # -> list[Any]:
        """
        returns a list of nodes reachable in an adjacency list from a
        specified root
        """
        ...
    
    def sort_pf_by_line(self, pf_id, parfors_simple): # -> int:
        """
        pd_id - the parfors id
        parfors_simple - the simple parfors map
        """
        ...
    
    def get_parfors_simple(self, print_loop_search): # -> dict[Any, Any]:
        ...
    
    def get_all_lines(self, parfors_simple): # -> dict[Any, Any]:
        ...
    
    def source_listing(self, parfors_simple, purpose_str): # -> None:
        ...
    
    def print_unoptimised(self, lines): # -> None:
        ...
    
    def print_optimised(self, lines): # -> None:
        ...
    
    def allocation_hoist(self): # -> None:
        ...
    
    def instruction_hoist(self): # -> None:
        ...
    
    def dump(self, level=...):
        ...
    
    def __str__(self) -> str:
        ...
    
    def __repr__(self): # -> Literal['ParforDiagnostics']:
        ...
    


class PreParforPass:
    """Preprocessing for the Parfor pass. It mostly inlines parallel
    implementations of numpy functions if available.
    """
    def __init__(self, func_ir, typemap, calltypes, typingctx, targetctx, options, swapped=..., replace_functions_map=...) -> None:
        ...
    
    def run(self): # -> None:
        """Run pre-parfor processing pass.
        """
        ...
    


def find_template(op): # -> None:
    ...

class ParforPassStates:
    """This class encapsulates all internal states of the ParforPass.
    """
    def __init__(self, func_ir, typemap, calltypes, return_type, typingctx, targetctx, options, flags, metadata, diagnostics=...) -> None:
        ...
    


class ConvertInplaceBinop:
    """Parfor subpass to convert setitem on Arrays
    """
    def __init__(self, pass_states) -> None:
        """
        Parameters
        ----------
        pass_states : ParforPassStates
        """
        ...
    
    def run(self, blocks): # -> None:
        ...
    


def get_index_var(x): # -> Var:
    ...

class ConvertSetItemPass:
    """Parfor subpass to convert setitem on Arrays
    """
    def __init__(self, pass_states) -> None:
        """
        Parameters
        ----------
        pass_states : ParforPassStates
        """
        ...
    
    def run(self, blocks): # -> None:
        ...
    


class ConvertNumpyPass:
    """
    Convert supported Numpy functions, as well as arrayexpr nodes, to
    parfor nodes.
    """
    def __init__(self, pass_states) -> None:
        ...
    
    def run(self, blocks): # -> None:
        ...
    


class ConvertReducePass:
    """
    Find reduce() calls and convert them to parfors.
    """
    def __init__(self, pass_states) -> None:
        ...
    
    def run(self, blocks): # -> None:
        ...
    


class ConvertLoopPass:
    """Build Parfor nodes from prange loops.
    """
    def __init__(self, pass_states) -> None:
        ...
    
    def run(self, blocks):
        ...
    


class ParforPass(ParforPassStates):
    """ParforPass class is responsible for converting NumPy
    calls in Numba intermediate representation to Parfors, which
    will lower into either sequential or parallel loops during lowering
    stage.
    """
    def run(self): # -> None:
        """run parfor conversion pass: replace Numpy calls
        with Parfors when possible and optimize the IR."""
        ...
    


class ParforFusionPass(ParforPassStates):
    """ParforFusionPass class is responsible for fusing parfors
    """
    def run(self): # -> None:
        """run parfor fusion pass"""
        ...
    
    def fuse_parfors(self, array_analysis, blocks, func_ir, typemap): # -> None:
        ...
    
    def fuse_recursive_parfor(self, parfor, equiv_set, func_ir, typemap): # -> None:
        ...
    


class ParforPreLoweringPass(ParforPassStates):
    """ParforPreLoweringPass class is responsible for preparing parfors for lowering.
    """
    def run(self): # -> None:
        """run parfor prelowering pass"""
        ...
    


def lower_parfor_sequential(typingctx, func_ir, typemap, calltypes, metadata): # -> None:
    ...

def get_parfor_params(blocks, options_fusion, fusion_info): # -> tuple[set[Any], list[Any]]:
    """find variables used in body of parfors from outside and save them.
    computed as live variables at entry of first block.
    """
    ...

def get_parfor_params_inner(parfor, pre_defs, options_fusion, fusion_info):
    ...

def get_array_indexed_with_parfor_index_internal(loop_body, index, ret_indexed, ret_not_indexed, nest_indices, func_ir): # -> None:
    ...

def get_array_indexed_with_parfor_index(loop_body, index, nest_indices, func_ir): # -> tuple[set[Any], set[Any]]:
    ...

def get_parfor_outputs(parfor, parfor_params): # -> list[Any]:
    """get arrays that are written to inside the parfor and need to be passed
    as parameters to gufunc.
    """
    ...

_RedVarInfo = ...
def get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions=..., reduce_varnames=..., param_uses=..., param_nodes=..., var_to_param=...): # -> tuple[Any | list[Any], Any | dict[Any, Any]]:
    """find variables that are updated using their previous values and an array
    item accessed with parfor index, e.g. s = s+A[i]
    """
    ...

def check_conflicting_reduction_operators(param, nodes): # -> None:
    """In prange, a user could theoretically specify conflicting
       reduction operators.  For example, in one spot it is += and
       another spot *=.  Here, we raise an exception if multiple
       different reduction operators are used in one prange.
    """
    ...

def get_reduction_init(nodes): # -> tuple[Literal[0], Any] | tuple[Literal[1], Any] | tuple[None, None]:
    """
    Get initial value for known reductions.
    Currently, only += and *= are supported.
    """
    ...

def supported_reduction(x, func_ir): # -> bool:
    ...

def get_reduce_nodes(reduction_node, nodes, func_ir): # -> None:
    """
    Get nodes that combine the reduction variable with a sentinel variable.
    Recognizes the first node that combines the reduction variable with another
    variable.
    """
    ...

def get_expr_args(expr): # -> list[Any]:
    """
    Get arguments of an expression node
    """
    ...

def visit_parfor_pattern_vars(parfor, callback, cbdata): # -> None:
    ...

def visit_vars_parfor(parfor, callback, cbdata): # -> None:
    ...

def parfor_defs(parfor, use_set=..., def_set=...): # -> use_defs_result:
    """list variables written in this parfor by recursively
    calling compute_use_defs() on body and combining block defs.
    """
    ...

def parfor_insert_dels(parfor, curr_dead_set): # -> set[Any | str]:
    """insert dels in parfor. input: dead variable set right after parfor.
    returns the variables for which del was inserted.
    """
    class DummyFuncIR:
        ...
    
    

def maximize_fusion(func_ir, blocks, typemap, up_direction=...): # -> None:
    """
    Reorder statements to maximize parfor fusion. Push all parfors up or down
    so they are adjacent.
    """
    ...

def maximize_fusion_inner(func_ir, block, call_table, alias_map, arg_aliases, up_direction=...): # -> bool:
    ...

def expand_aliases(the_set, alias_map, arg_aliases): # -> set[Any]:
    ...

def is_assert_equiv(func_ir, expr): # -> bool:
    ...

def get_parfor_writes(parfor): # -> set[Any]:
    ...

FusionReport = ...
def try_fuse(equiv_set, parfor1, parfor2, metadata, func_ir, typemap): # -> tuple[None, FusionReport] | tuple[Any, FusionReport]:
    """try to fuse parfors and return a fused parfor, otherwise return None
    """
    ...

def fuse_parfors_inner(parfor1, parfor2): # -> tuple[Any, FusionReport]:
    ...

def remove_duplicate_definitions(blocks, nameset): # -> None:
    """Remove duplicated definition for variables in the given nameset, which
    is often a result of parfor fusion.
    """
    ...

def has_cross_iter_dep(parfor, func_ir, typemap, index_positions=..., indexed_arrays=..., non_indexed_arrays=...): # -> tuple[Literal[True], Any | dict[Any, Any], set[Any] | Any, set[Any] | Any] | tuple[Literal[False], Any | dict[Any, Any], set[Any] | Any, set[Any] | Any]:
    ...

def dprint(*s): # -> None:
    ...

def get_parfor_pattern_vars(parfor): # -> set[Any]:
    """ get the variables used in parfor pattern information
    """
    ...

def remove_dead_parfor(parfor, lives, lives_n_aliases, arg_aliases, alias_map, func_ir, typemap): # -> None:
    """ remove dead code inside parfor including get/sets
    """
    ...

def remove_dead_parfor_recursive(parfor, lives, arg_aliases, alias_map, func_ir, typemap): # -> None:
    """create a dummy function from parfor and call remove dead recursively
    """
    ...

def find_potential_aliases_parfor(parfor, args, typemap, func_ir, alias_map, arg_aliases): # -> None:
    ...

def simplify_parfor_body_CFG(blocks): # -> int:
    """simplify CFG of body loops in parfors"""
    ...

def wrap_parfor_blocks(parfor, entry_label=...):
    """wrap parfor blocks for analysis/optimization like CFG"""
    ...

def unwrap_parfor_blocks(parfor, blocks=...): # -> None:
    """
    unwrap parfor blocks after analysis/optimization.
    Allows changes to the parfor loop.
    """
    ...

def get_copies_parfor(parfor, typemap): # -> tuple[Any, Any]:
    """find copies generated/killed by parfor"""
    ...

def apply_copies_parfor(parfor, var_dict, name_var_table, typemap, calltypes, save_copies): # -> None:
    """apply copy propagate recursively in parfor"""
    ...

def push_call_vars(blocks, saved_globals, saved_getattrs, typemap, nested=...): # -> None:
    """push call variables to right before their call site.
    assuming one global/getattr is created for each call site and control flow
    doesn't change it.
    """
    ...

def repr_arrayexpr(arrayexpr): # -> str:
    """Extract operators from arrayexpr to represent it abstractly as a string.
    """
    ...

def fix_generator_types(generator_info, return_type, typemap): # -> None:
    """postproc updates generator_info with live variables after transformations
    but generator variables have types in return_type that are updated here.
    """
    ...

def get_parfor_call_table(parfor, call_table=..., reverse_call_table=...): # -> tuple[Any | dict[Any, Any], Any | dict[Any, Any]]:
    ...

def get_parfor_tuple_table(parfor, tuple_table=...): # -> dict[Any, Any]:
    ...

def get_parfor_array_accesses(parfor, accesses=...): # -> set[Any]:
    ...

def parfor_add_offset_to_labels(parfor, offset): # -> None:
    ...

def parfor_find_max_label(parfor): # -> Literal[0]:
    ...

def parfor_typeinfer(parfor, typeinferer): # -> None:
    ...

def build_parfor_definitions(parfor, definitions=...): # -> defaultdict[Any, list[Any]]:
    """get variable definition table for parfors"""
    ...

@contextmanager
def dummy_return_in_loop_body(loop_body): # -> Generator[None, Any, None]:
    """adds dummy return to last block of parfor loop body for CFG computation
    """
    ...

@infer_global(reduce)
class ReduceInfer(AbstractTemplate):
    def generic(self, args, kws): # -> Signature:
        ...
    


def ensure_parallel_support(): # -> None:
    """Check if the platform supports parallel=True and raise if it does not.
    """
    ...

