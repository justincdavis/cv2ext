# Copyright (c) 2024 Justin Davis (davisjustin302@gmail.com)
#
# MIT License
# ruff: noqa: S311
from __future__ import annotations

import math
import random
from abc import ABC, abstractmethod
from typing import TYPE_CHECKING

import numpy as np

from cv2ext._jit import register_jit
from cv2ext.bboxes._bounding import _bounding_kernel

if TYPE_CHECKING:
    from typing_extensions import Self


class AbstractFramePacker(ABC):
    """
    Pack regions of a frame together based on detection activity.

    Detections are represented as a list of bounding boxes with
    scores and class id labels optional.
    """

    @abstractmethod
    def pack(
        self: Self,
        image: np.ndarray,
        exclude: tuple[int, int, int, int] | list[tuple[int, int, int, int]],
    ) -> tuple[np.ndarray, np.ndarray]:
        """
        Pack regions of a frame together.

        Parameters
        ----------
        image : np.ndarray
            The image to pack.
        exclude : tuple[int, int, int, int] | list[tuple[int, int, int, int]]
            Regions of the image to exclude from the packing.

        Returns
        -------
        tuple[np.ndarray, np.ndarray]
            The packed image and the transform information.

        """

    @abstractmethod
    def unpack(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
        transform: np.ndarray,
    ) -> (
        list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]]
    ):
        """
        Unpack regions of a frame.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The regions to unpack.
        transform : np.ndarray
            The transform information generated by the pack method.

        Returns
        -------
        list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]

        """

    @abstractmethod
    def update(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
    ) -> None:
        """
        Update the packer with new detections.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The detections to update the packer with.

        """

    @abstractmethod
    def reset(self: Self, image_shape: tuple[int, int] | None = None) -> None:
        """
        Reset the packer.

        Parameters
        ----------
        image_shape : tuple[int, int] | None
            The shape of the image in form (height, width).

        """


@register_jit()
def _bbox_to_gridcells(
    bbox: tuple[int, int, int, int],
    row_step: int,
    col_step: int,
    n_rows: int,
    n_cols: int,
) -> list[tuple[int, int]]:
    x1, y1, x2, y2 = bbox
    min_row = max(0, math.floor(y1 / row_step))
    max_row = min(n_rows, math.ceil(y2 / row_step))
    min_col = max(0, math.floor(x1 / col_step))
    max_col = min(n_cols, math.ceil(x2 / col_step))

    cells: list[tuple[int, int]] = []
    for i in range(min_row, max_row):
        for j in range(min_col, max_col):
            cells.extend([(i, j)])
    return cells


@register_jit()
def _bboxes_to_gridcells(
    bboxes: list[tuple[int, int, int, int]],
    row_step: int,
    col_step: int,
    n_rows: int,
    n_cols: int,
) -> set[tuple[int, int]]:
    cells: list[tuple[int, int]] = []
    for bbox in bboxes:
        cells.extend(_bbox_to_gridcells(bbox, row_step, col_step, n_rows, n_cols))
    return set(cells)


@register_jit()
def _unpack_grid_single_bbox(
    bbox: tuple[int, int, int, int],
    transform: np.ndarray,
    gridsize: int,
) -> tuple[int, int, int, int]:
    x1, y1, x2, y2 = bbox

    # Determine grid coordinates for the packed bounding box
    n_col = int(((x1 + x2) / 2.0) // gridsize)
    n_row = int(((y1 + y2) / 2.0) // gridsize)

    # clamp indices
    n_row = max(0, min(n_row, transform.shape[0] - 1))
    n_col = max(0, min(n_col, transform.shape[1] - 1))

    # Retrieve original top-left offset for the grid cell
    o_x, o_y = transform[n_row][n_col]

    # Calculate the absolute coordinates in the original image
    abs_x1 = x1 - (n_col * gridsize) + o_x
    abs_y1 = y1 - (n_row * gridsize) + o_y
    abs_x2 = x2 - (n_col * gridsize) + o_x
    abs_y2 = y2 - (n_row * gridsize) + o_y

    return abs_x1, abs_y1, abs_x2, abs_y2


@register_jit()
def _unpack_grid_bboxes_conf_classid(
    detections: list[tuple[tuple[int, int, int, int], float, int]],
    transform: np.ndarray,
    gridsize: int,
) -> list[tuple[tuple[int, int, int, int], float, int]]:
    unpacked_dets: list[tuple[tuple[int, int, int, int], float, int]] = []
    for bbox, conf, classid in detections:
        abs_x1, abs_y1, abs_x2, abs_y2 = _unpack_grid_single_bbox(
            bbox,
            transform,
            gridsize,
        )

        # Append the unpacked detection
        unpacked_dets.append(((abs_x1, abs_y1, abs_x2, abs_y2), conf, classid))
    return unpacked_dets


@register_jit()
def _unpack_grid_bboxes(
    detections: list[tuple[int, int, int, int]],
    transform: np.ndarray,
    gridsize: int,
) -> list[tuple[int, int, int, int]]:
    unpacked_dets: list[tuple[int, int, int, int]] = []
    for bbox in detections:
        abs_x1, abs_y1, abs_x2, abs_y2 = _unpack_grid_single_bbox(
            bbox,
            transform,
            gridsize,
        )

        # Append the unpacked detection
        unpacked_dets.append((abs_x1, abs_y1, abs_x2, abs_y2))
    return unpacked_dets


@register_jit()
def _simple_grid_repack(
    image: np.ndarray,
    cells: list[tuple[tuple[int, int, int, int], tuple[int, int]]],
    gridsize: int,
) -> tuple[np.ndarray, np.ndarray]:
    # need to repack the cells into a new image
    num_cells = len(cells)
    dim1 = max(1, math.ceil(math.sqrt(num_cells)))
    dim2 = max(1, math.ceil(num_cells / dim1))

    # allocate new data for the patches
    new_image: np.ndarray = np.zeros(
        (dim2 * gridsize, dim1 * gridsize, 3),
        dtype=np.uint8,
    )

    # copy the old data into new packed image
    # generate the transforms
    # new_grids: np.ndarray = np.zeros((self._n_rows, self._n_cols, 2), dtype=int)
    new_grids: np.ndarray = np.zeros((dim2, dim1, 2), dtype=int)
    for i, (bbox, _) in enumerate(cells):
        x1, y1, x2, y2 = bbox

        # generate the new row/col
        n_row = math.floor(i / dim1)  # Fixed dimension calculation
        n_col = i % dim1

        # generate the new bounding box
        n_x1 = n_col * gridsize
        n_x2 = n_x1 + gridsize
        n_y1 = n_row * gridsize
        n_y2 = n_y1 + gridsize

        # generate the offset, same as old coords for x1, y1
        offset = (x1, y1)

        # perform the data copy
        new_image[n_y1:n_y2, n_x1:n_x2] = image[y1:y2, x1:x2]

        # save the new grid entry
        new_grids[n_row, n_col] = offset

    return new_image, new_grids


@register_jit()
def _connected_components_grid_repack(
    image: np.ndarray,
    cells: list[tuple[tuple[int, int, int, int], tuple[int, int]]],
    gridsize: int,
) -> tuple[np.ndarray, np.ndarray]:
    # identify connected components
    matched: set[tuple[int, int]] = set()
    to_match: set[tuple[int, int]] = set()
    for cell in cells:
        to_match.add(cell[1])
    groups: list[
        tuple[
            list[tuple[int, int, int, int]],
            list[tuple[int, int]],
        ],
    ] = []
    for idx1, (cell1, loc1) in enumerate(cells):
        if loc1 in matched:
            continue

        group_hash: set[tuple[int, int]] = set()
        group_locs: list[tuple[int, int]] = [loc1]
        group_boxes: list[tuple[int, int, int, int]] = [cell1]
        matched.add(loc1)
        group_hash.add(loc1)

        for idx2, (cell2, loc2) in enumerate(cells):
            if idx1 == idx2:
                continue

            if loc2 in matched:
                continue

            # if not same cell and not matched already see if we can find a match
            # check if the cells are adjacent (non-diagonal)
            potentials = [
                (loc2[0] - 1, loc2[1]),
                # (loc2[0] + 1, loc2[1]),
                (loc2[0], loc2[1] - 1),
                # (loc2[0], loc2[1] + 1),
            ]
            # trim the potential cells
            potentials = [p for p in potentials if p[0] >= 0 and p[1] >= 0]
            valid_potentials = 0
            for ploc in potentials:
                if ploc in group_hash:
                    valid_potentials += 1

            # if the two previous cells we check are in the matched set
            # then we add this one as well
            if valid_potentials >= 1:
                group_locs.append(loc2)
                group_boxes.append(cell2)
                matched.add(loc2)
                group_hash.add(loc2)

        groups.append((group_boxes, group_locs))

    print(len(cells), "->", len(groups))

    if len(groups) != 1:
        print("Could not perfectly reduce")

    # compute info for each grouping of bounding boxes
    all_tiles: int = 0
    group_info: list[tuple[tuple[int, int, int, int], list[tuple[int, int, int, int]], list[tuple[int, int]], int, int, int]] = []
    for boxes, locs in groups:
        # compute overall information about the group, since we do not maintain a "frontier" for cells
        rows = [loc[0] for loc in locs]
        cols = [loc[1] for loc in locs]
        min_col = min(cols)
        max_col = max(cols)
        min_row = min(rows)
        max_row = max(rows)
        group_width = max_col - min_col + 1
        group_height = max_row - min_row + 1
        group_size = group_width * group_height
        all_tiles += group_size
        overall_bounding = _bounding_kernel(boxes)
        group_info.append((
            overall_bounding,
            boxes,
            locs,
            group_height,
            group_width,
            group_size,
        ))
    group_info.sort(key=lambda e: e[-1], reverse=True)

    # compute the ideal size in loc coords
    target_dim = math.ceil(math.sqrt(all_tiles))

    # each shelf is [left, right, bottom, list of groups]
    shelves: list[tuple[int, int, int, list[tuple[list[tuple[int, int, int, int]], list[tuple[int, int]]]]]] = []
    for group in group_info:
        _, boxes, locs, height, width, _ = group
        # simple case where no shelves created yet
        if len(shelves) == 0:
            shelves.append(
                (0, width, height, [(boxes, locs)]),
            )
            continue

        # otherwise we have to find the best fit
        best_idx = -1
        max_w = 0
        for idx, (s_left, s_right, s_height, _) in enumerate(shelves):
            s_width = s_right - s_left

            # update our frontier
            max_w = s_right

            # if room in the shelf in the height, keep adding
            if width <= s_width and height + s_height < target_dim:
                best_idx = idx
                break

        if best_idx == -1:
            shelves.append((max_w, max_w + width, height, [(boxes, locs)]))
        else:
            s_left, s_right, s_height, s_boxes = shelves[best_idx]

            s_height += height
            s_boxes.append((boxes, locs))

            shelves[best_idx] = (s_left, s_right, s_height, s_boxes)

    # get max dimensions
    grid_width = shelves[-1][1]
    grid_height = max(shelves, key=lambda s: s[2])[2]

    # allocate a new image
    img_h = max(gridsize, grid_height * gridsize)
    img_w = max(gridsize, grid_width * gridsize)
    new_image = np.zeros((img_h, img_w, 3), dtype=np.uint8)

    # allocate the transform array
    new_grids = np.zeros((grid_height, grid_width, 2), dtype=int)

    print((grid_height, grid_width, 2))

    current_shelf_y = 0
    # iterate over each shelf
    for shelf_idx, shelf in enumerate(shelves):
        print(f"Shelf: {shelf_idx}")
        shelf_x_start, shelf_x_end, shelf_height, groups_in_shelf = shelf
        # within the shelf, we will pack groups from left to right.
        current_group_y = 0  # starting x offset for this shelf

        for group_idx, group in enumerate(groups_in_shelf):
            print(f"Group: {group_idx}")
            boxes, locs = group

            # determine the minimal grid coordinates for this group;
            # this will serve as the group “origin” so that we pack the group tightly.
            group_min_x = min(loc[1] for loc in locs)
            group_min_y = min(loc[0] for loc in locs)
            group_max_x = max(loc[1] for loc in locs)
            group_max_y = max(loc[0] for loc in locs)
            group_width = group_max_x - group_min_x + 1
            group_height = group_max_y - group_min_y + 1

            # now iterate over each cell (its bounding box and original grid location)
            # and compute its new location.
            # boxes are ordered so get the base box
            for box, loc in zip(boxes, locs):
                # determine new grid coordinates: the cell's offset inside the group
                # is (loc - (group_min_x, group_min_y)) then add the shelf offsets.
                new_grid_x = shelf_x_start + (loc[1] - group_min_x)
                new_grid_y = current_group_y + (loc[0] - group_min_y)

                print((new_grid_y, new_grid_x), loc)

                # update the transform grid; here we simply store the original grid location.
                new_grids[new_grid_y][new_grid_x] = loc

                # now copy the image data.
                # Here we assume that each cell's image is exactly of size `gridsize` by `gridsize`.
                # The source cell region is defined by its bounding box (assumed to be (x1, y1, x2, y2)).
                # The destination region is computed from the new grid cell coordinates.
                dst_y1 = new_grid_y * gridsize
                dst_y2 = dst_y1 + gridsize
                dst_x1 = new_grid_x * gridsize
                dst_x2 = dst_x1 + gridsize

                src_x1, src_y1, src_x2, src_y2 = box
                new_image[dst_y1:dst_y2, dst_x1:dst_x2, :] = image[src_y1:src_y2, src_x1:src_x2, :]

            # # after processing one group, update the x offset in the shelf.
            shelf_x_start += group_height

        # # after finishing all groups in the shelf, update the y offset.
        # current_shelf_y += shelf[2]  # shelf[2] is 

    return new_image, new_grids


# CHATGPT PROVIDED FUNCTION
def _intelligent_grid_repack(
    image: np.ndarray,
    cells: list[tuple[tuple[int, int, int, int], tuple[int, int]]],
    gridsize: int,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Repack image cells into a new image.

    Try to keep together
    groups of adjacent cells. We assume that cells that are adjacent in the
    original image always form a perfect square block (i.e. an NxN region).

    Parameters
    ----------
    image: the source image.
    cells: a list of tuples (bbox, offset) where bbox is (x1, y1, x2, y2).
            We assume each bbox corresponds to a cell that is exactly `gridsize`
            pixels on a side.
    gridsize: the size (in pixels) of one cell.

    Returns
    -------
    new_image: a repacked image containing the same cells.
    new_grids: a 2D array (of shape (new_rows, new_cols, 2)) where each entry
                records the original (x1, y1) offset of the cell that ended up
                at that grid location.

    """
    ###########################################################################
    # Step 1. Identify groups of adjacent cells.
    #
    # We assume that each cell’s bounding box is aligned to a grid so that we
    # can compute an “original cell coordinate” by (row, col) = (y1//gridsize, x1//gridsize).
    #
    # Then we “group” cells into squares: starting from a cell (r, c), we try to
    # see how big a square block can be formed by checking that all cells at
    # (r+i, c+j) exist.
    ###########################################################################
    # Build a mapping from grid coordinate to cell information.
    cell_dict = {}
    for cell in cells:
        bbox, offset = cell
        x1, y1, x2, y2 = bbox
        # Compute grid coordinate of the cell’s top‐left
        grid_row = y1 // gridsize
        grid_col = x1 // gridsize
        cell_dict[(grid_row, grid_col)] = (bbox, offset)

    visited = set()
    groups = []  # Each group: ((r, c), group_size, group_cells)
    # (group_cells will be a list-of-lists (rows) preserving the cell order)

    # Iterate over all possible grid locations (in sorted order)
    for (r, c) in sorted(cell_dict.keys()):
        if (r, c) in visited:
            continue

        # Starting at (r, c) determine the largest square block that exists.
        n = 1  # try 1×1, 2×2, etc.
        while True:
            valid = True
            # Check that all cells (r+i, c+j) for i,j in 0..n-1 exist and are not already used.
            for i in range(n):
                for j in range(n):
                    if (r + i, c + j) not in cell_dict or ((r + i, c + j) in visited):
                        valid = False
                        break
                if not valid:
                    break
            if valid:
                n += 1
            else:
                break
        group_size = n - 1  # maximum square block size found

        # Collect the group cells in row-major order.
        group_cells = []
        for i in range(group_size):
            row_cells = []
            for j in range(group_size):
                cell_info = cell_dict[(r + i, c + j)]
                row_cells.append(cell_info)
                visited.add((r + i, c + j))
            group_cells.append(row_cells)
        groups.append(((r, c), group_size, group_cells))
    # Sort groups by their original top‐left coordinate.
    groups.sort(key=lambda g: g[0])

    ###########################################################################
    # Step 2. Decide on the overall layout.
    #
    # We want to pack the cells (still thinking in “cell units”) into a roughly
    # square new grid while ensuring that no group is split.
    #
    # One strategy is to compute a target width (in cells) from the total number
    # of cells, then pack groups into rows: if the next group would overflow the
    # target width, we start a new row.
    ###########################################################################
    total_cell_count = len(cells)  # sum of all group sizes^2
    target_width = max(1, math.ceil(math.sqrt(total_cell_count)))

    # Pack groups into rows. Each row will be a list of groups.
    group_rows = []  # Each element: (list_of_groups, row_width_in_cells, row_height_in_cells)
    current_row = []
    current_row_width = 0
    current_row_height = 0  # In cell units (each group is square)
    for group in groups:
        _, group_size, _ = group
        # If there is at least one group already in the row and adding this group
        # would exceed our target width, then finish the current row.
        if current_row and (current_row_width + group_size > target_width):
            group_rows.append((current_row, current_row_width, current_row_height))
            current_row = []
            current_row_width = 0
            current_row_height = 0
        current_row.append(group)
        current_row_width += group_size
        current_row_height = max(current_row_height, group_size)
    if current_row:
        group_rows.append((current_row, current_row_width, current_row_height))

    # Compute overall new grid dimensions in “cell units”
    new_grid_rows = sum(row_height for (_, _, row_height) in group_rows)
    new_grid_cols = max(row_width for (_, row_width, _) in group_rows)

    ###########################################################################
    # Step 3. Allocate the new image (in pixels) and new grids array.
    ###########################################################################
    new_image = np.zeros((new_grid_rows * gridsize, new_grid_cols * gridsize, 3), dtype=np.uint8)
    new_grids = np.zeros((new_grid_rows, new_grid_cols, 2), dtype=int)

    ###########################################################################
    # Step 4. Copy the cell patches into the new image.
    #
    # For each group (which itself is a square block of cells), copy each cell’s
    # image data into the corresponding new “cell” location. The relative layout
    # within a group is preserved.
    ###########################################################################
    current_cell_row = 0  # running count of cell-rows in the repacked grid
    for (groups_in_row, _, row_height) in group_rows:
        current_cell_col = 0  # reset column for each new row of groups
        # For each group in the current row:
        for group in groups_in_row:
            _, group_size, group_cells = group
            # Place the group’s cells starting at (current_cell_row, current_cell_col)
            for i in range(group_size):
                for j in range(group_size):
                    bbox, offset = group_cells[i][j]
                    # Compute destination pixel coordinates
                    dest_row = current_cell_row + i
                    dest_col = current_cell_col + j
                    y1_dest = dest_row * gridsize
                    y2_dest = y1_dest + gridsize
                    x1_dest = dest_col * gridsize
                    x2_dest = x1_dest + gridsize

                    # Unpack the source bbox.
                    x1_src, y1_src, x2_src, y2_src = bbox
                    new_image[y1_dest:y2_dest, x1_dest:x2_dest] = image[y1_src:y2_src, x1_src:x2_src]
                    new_grids[dest_row, dest_col] = offset
            # Advance by the group’s width (in cell units)
            current_cell_col += group_size
        # After placing all groups in this row, move down by the row height.
        current_cell_row += row_height

    return new_image, new_grids


class AbstractGridFramePacker(AbstractFramePacker):
    """Pack regions of a frame together based on a grid."""

    def __init__(
        self: Self,
        image_shape: tuple[int, int],
        gridsize: int = 128,
        detection_buffer: int = 30,
        method: str = "simple",
    ) -> None:
        """
        Create a new GridFramePacker.

        Parameters
        ----------
        image_shape : tuple[int, int]
            The shape of the image in form (width, height).
        gridsize : int, optional
            The size of each cell in the overlaid grid.
            Default is 128.
        detection_buffer : int, optional
            The number of frames to consider for detection activity.
            Used instead of current frame count once frame count exceeds buffer size.
            Allows more recent detections to have more influence.
            Default is 30.
        method : str, optional
            The method to use for repacking grid cells into new images.
            By default, 'simple'
            Options are: ['simple', 'smart']
            Simple will place tiles of the grid FCFS basis in the new image,
            while smart will attempt to place connected regions together.

        """
        super().__init__()
        self._width, self._height = image_shape
        self._gridsize = gridsize
        self._detection_buffer = detection_buffer
        self._method = method

        # assign type hints to variables used in initialize_cells
        self._n_cols: int
        self._n_rows: int
        self._col_step: int
        self._row_step: int
        self._num_dets: np.ndarray
        self._cells: np.ndarray

        self._initialize_cells()

        # tracking variables
        self._counter: int = 0

    def reset(self: Self, image_shape: tuple[int, int] | None = None) -> None:
        """
        Reset the packer.

        Parameters
        ----------
        image_shape : tuple[int, int] | None
            The shape of the image in form (height, width).

        """
        if image_shape:
            self._height, self._width = image_shape
        self._initialize_cells()
        self._counter = 0

    def _initialize_cells(self: Self) -> None:
        """Initialize the grid cells and related parameters."""
        # num rows/cols
        self._n_cols = math.ceil(self._width / self._gridsize)
        self._n_rows = math.ceil(self._height / self._gridsize)

        # step size between grid cells
        self._col_step = (
            int((self._width - self._gridsize) / (self._n_cols - 1))
            if self._n_cols > 1
            else self._width
        )
        self._row_step = (
            int((self._height - self._gridsize) / (self._n_rows - 1))
            if self._n_rows > 1
            else self._height
        )

        # detection count info
        self._num_dets = np.zeros((self._n_rows, self._n_cols), dtype=int)

        # create the cell setup
        self._cells = np.zeros((self._n_rows * self._n_cols, 6), dtype=int)
        index: int = 0
        for i in range(self._n_rows):
            for j in range(self._n_cols):
                v_off = i * self._row_step
                h_off = j * self._col_step
                bbox = (
                    h_off,
                    v_off,
                    h_off + self._gridsize,
                    v_off + self._gridsize,
                )
                self._cells[index, :4] = bbox
                self._cells[index, 4:] = (i, j)
                index += 1

    @abstractmethod
    def _should_explore(
        self: Self,
        image: np.ndarray,
        bbox: tuple[int, int, int, int],
        row: int,
        col: int,
        detections: int,
    ) -> bool:
        """
        Whether to explore a grid cell based on detection activity.

        Parameters
        ----------
        image : np.ndarray
            The image to be packed.
        bbox : tuple[int, int, int, int]
            The bounding box of the cell.
        row : int
            The row of the cell.
        col : int
            The column of the cell.
        detections : int
            The number of detections in the cell.

        Returns
        -------
        bool
            Whether to explore the cell.

        """

    def pack(
        self,
        image: np.ndarray,
        exclude: tuple[int, int, int, int]
        | list[tuple[int, int, int, int]]
        | None = None,
        method: str | None = None,
    ) -> tuple[np.ndarray, np.ndarray]:
        """
        Pack regions of a frame together.

        Parameters
        ----------
        image : np.ndarray
            The image to pack.
        exclude : tuple[int, int, int, int] | list[tuple[int, int, int, int]], optional
            Regions of the image to exclude from the packing.
            By default None.
        method : str, optional
            The method to pack the bounding boxes with.
            By default, None
            Options are: ['simple', 'smart']

        Returns
        -------
        tuple[np.ndarray, np.ndarray]
            The packed image and the transform information.

        Raises
        ------
        ValueError
            If the image shape does not match the packer shape.

        """
        height, width = image.shape[:2]
        if height != self._height or width != self._width:
            err_msg = f"Image shape {image.shape} does not match packer shape {self._height, self._width}."
            raise ValueError(err_msg)

        # get the excluded cells
        excluded_cells: set[tuple[int, int]] = set()
        if exclude is not None and len(exclude) > 0:
            if isinstance(exclude, tuple):
                excluded_cells = set(
                    _bbox_to_gridcells(
                        exclude,
                        self._row_step,
                        self._col_step,
                        self._n_rows,
                        self._n_cols,
                    ),
                )
            else:
                excluded_cells = _bboxes_to_gridcells(
                    exclude,
                    self._row_step,
                    self._col_step,
                    self._n_rows,
                    self._n_cols,
                )

        # get all cells which are not in the excluded region
        included_cells = [
            (x1, y1, x2, y2, r, c)
            for (x1, y1, x2, y2, r, c) in self._cells
            if (r, c) not in excluded_cells
        ]

        # need to assess if the cells should be included based on detections and NCC
        filtered_cells: list[tuple[tuple[int, int, int, int], tuple[int, int]]] = []
        for x1, y1, x2, y2, row, col in included_cells:
            bbox = (x1, y1, x2, y2)
            if self._should_explore(
                image,
                bbox,
                row,
                col,
                self._num_dets[row][col],
            ):
                filtered_cells.append((bbox, (row, col)))

        # use the simple grid repacking
        method = method if method else self._method
        if method == "simple":
            new_image, new_grids = _simple_grid_repack(
                image,
                filtered_cells,
                self._gridsize,
            )
        else:
            new_image, new_grids = _intelligent_grid_repack(
                image,
                filtered_cells,
                self._gridsize,
            )

        # update the image
        self._prev_image = image
        self._counter += 1

        return new_image, new_grids

    def unpack(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
        transform: np.ndarray,
    ) -> (
        list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]]
    ):
        """
        Unpack regions of a frame.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The regions to unpack.
        transform : np.ndarray
            The transform information generated by the pack method.

        Returns
        -------
        list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]

        """
        if len(detections) == 0:
            return []

        # get the type of detections passed
        if len(detections[0]) == 3:
            return _unpack_grid_bboxes_conf_classid(
                detections,  # type: ignore[arg-type]
                transform,
                self._gridsize,
            )

        return _unpack_grid_bboxes(detections, transform, self._gridsize)  # type: ignore[arg-type]

    def update(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
    ) -> None:
        """
        Update the packer with new detections.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The detections to update the packer with.

        """
        # add det counts to all possible grids with detections
        for elements in detections:
            if len(elements) == 3:
                bbox, _, _ = elements
            else:
                bbox = elements

            # get the grid cells that the bbox intersects
            grids = _bbox_to_gridcells(
                bbox,
                self._row_step,
                self._col_step,
                self._n_rows,
                self._n_cols,
            )

            # increment the detection count for each grid cell
            for o_row, o_col in grids:
                if 0 <= o_row < self._n_rows and 0 <= o_col < self._n_cols:
                    self._num_dets[o_row][o_col] += 1

        # decrement all counters by 1
        self._num_dets = np.maximum(0, self._num_dets - 1)


class AnnealingFramePacker(AbstractGridFramePacker):
    """
    Pack regions of a frame together based on detection activity.

    Detections are represented as a list of bounding boxes with
    scores and class id labels optional.
    """

    def __init__(
        self: Self,
        image_shape: tuple[int, int],
        gridsize: int = 128,
        alpha: float = 0.01,
        min_prob: float = 0.1,
        detection_buffer: int = 30,
        method: str = "simple",
    ) -> None:
        """
        Create a new AnnealingFramePacker.

        Parameters
        ----------
        image_shape : tuple[int, int]
            The shape of the image in form (width, height).
        gridsize : int, optional
            The size of each cell in the overlaid grid.
            Default is 128.
        alpha : float, optional
            The learning rate for the annealing process.
            Default is 0.01.
        min_prob : float, optional
            The minimum probability for a region to be considered active.
            Default is 0.1.
        detection_buffer : int, optional
            The number of frames to consider for detection activity.
            Used instead of current frame count once frame count exceeds buffer size.
            Allows more recent detections to have more influence.
            Default is 30.
        method : str, optional
            The method to use for repacking grid cells into new images.
            By default, 'simple'
            Options are: ['simple', 'smart']
            Simple will place tiles of the grid FCFS basis in the new image,
            while smart will attempt to place connected regions together.

        """
        super().__init__(image_shape, gridsize, detection_buffer, method)

        # specific annealing parameters
        self._alpha = alpha
        self._min_prob = min_prob

    def _should_explore(
        self: Self,
        image: np.ndarray,  # noqa: ARG002
        bbox: tuple[int, int, int, int],  # noqa: ARG002
        row: int,  # noqa: ARG002
        col: int,  # noqa: ARG002
        detections: int,
    ) -> bool:
        time_factor = math.exp(-self._alpha * self._counter)
        detection_factor = min(
            1.0,
            detections / (min(self._counter, self._detection_buffer - 1) + 1),
        )
        explore_probability = max(self._min_prob, time_factor + detection_factor)
        return random.random() < explore_probability


class RandomFramePacker(AbstractGridFramePacker):
    """Pack regions of a frame together randomly."""

    def __init__(
        self: Self,
        image_shape: tuple[int, int],
        gridsize: int = 128,
        threshold: float = 0.1,
        detection_buffer: int = 30,
        method: str = "simple",
    ) -> None:
        """
        Create a new RandomFramePacker.

        Parameters
        ----------
        image_shape : tuple[int, int]
            The shape of the image in form (width, height).
        gridsize : int, optional
            The size of each cell in the overlaid grid.
            Default is 128.
        threshold : float, optional
            The threshold for which to randomly explore a grid cell.
            If the random value is less than the threshold, the cell is explored.
            Threshold of 0.1 means 10% of the time a cell is explored.
            Default is 0.1.
        detection_buffer : int, optional
            The number of frames to consider for detection activity.
            Used instead of current frame count once frame count exceeds buffer size.
            Allows more recent detections to have more influence.
            Default is 30.
        method : str, optional
            The method to use for repacking grid cells into new images.
            By default, 'simple'
            Options are: ['simple', 'smart']
            Simple will place tiles of the grid FCFS basis in the new image,
            while smart will attempt to place connected regions together.

        """
        super().__init__(image_shape, gridsize, detection_buffer, method)

        # specific parameters
        self._threshold = threshold

    def _should_explore(
        self: Self,
        image: np.ndarray,  # noqa: ARG002
        bbox: tuple[int, int, int, int],  # noqa: ARG002
        row: int,  # noqa: ARG002
        col: int,  # noqa: ARG002
        detections: int,  # noqa: ARG002
    ) -> bool:
        return random.random() < self._threshold
