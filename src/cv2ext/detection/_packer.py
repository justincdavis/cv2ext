# Copyright (c) 2024 Justin Davis (davisjustin302@gmail.com)
#
# MIT License
# ruff: noqa: S311
from __future__ import annotations

import math
import random
from abc import ABC, abstractmethod
from typing import TYPE_CHECKING

import numpy as np

from cv2ext._jit import register_jit

if TYPE_CHECKING:
    from typing_extensions import Self


class AbstractFramePacker(ABC):
    """
    Pack regions of a frame together based on detection activity.

    Detections are represented as a list of bounding boxes with
    scores and class id labels optional.
    """

    @abstractmethod
    def pack(
        self: Self,
        image: np.ndarray,
        exclude: tuple[int, int, int, int] | list[tuple[int, int, int, int]],
    ) -> tuple[np.ndarray, np.ndarray]:
        """
        Pack regions of a frame together.

        Parameters
        ----------
        image : np.ndarray
            The image to pack.
        exclude : tuple[int, int, int, int] | list[tuple[int, int, int, int]]
            Regions of the image to exclude from the packing.

        Returns
        -------
        tuple[np.ndarray, np.ndarray]
            The packed image and the transform information.

        """

    @abstractmethod
    def unpack(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
        transform: np.ndarray,
    ) -> (
        list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]]
    ):
        """
        Unpack regions of a frame.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The regions to unpack.
        transform : np.ndarray
            The transform information generated by the pack method.

        Returns
        -------
        list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]

        """

    @abstractmethod
    def update(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
    ) -> None:
        """
        Update the packer with new detections.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The detections to update the packer with.

        """

    @abstractmethod
    def reset(self: Self, image_shape: tuple[int, int] | None = None) -> None:
        """
        Reset the packer.

        Parameters
        ----------
        image_shape : tuple[int, int] | None
            The shape of the image in form (height, width).

        """


@register_jit()
def _bbox_to_gridcells(
    bbox: tuple[int, int, int, int],
    row_step: int,
    col_step: int,
    n_rows: int,
    n_cols: int,
) -> list[tuple[int, int]]:
    x1, y1, x2, y2 = bbox
    min_row = max(0, math.floor(y1 / row_step))
    max_row = min(n_rows, math.ceil(y2 / row_step))
    min_col = max(0, math.floor(x1 / col_step))
    max_col = min(n_cols, math.ceil(x2 / col_step))

    cells: list[tuple[int, int]] = []
    for i in range(min_row, max_row):
        for j in range(min_col, max_col):
            cells.extend([(i, j)])
    return cells


@register_jit()
def _bboxes_to_gridcells(
    bboxes: list[tuple[int, int, int, int]],
    row_step: int,
    col_step: int,
    n_rows: int,
    n_cols: int,
) -> set[tuple[int, int]]:
    cells: list[tuple[int, int]] = []
    for bbox in bboxes:
        cells.extend(_bbox_to_gridcells(bbox, row_step, col_step, n_rows, n_cols))
    return set(cells)


@register_jit()
def _unpack_grid_single_bbox(
    bbox: tuple[int, int, int, int],
    transform: np.ndarray,
    gridsize: int,
) -> tuple[int, int, int, int]:
    x1, y1, x2, y2 = bbox

    # Determine grid coordinates for the packed bounding box
    n_col = int(((x1 + x2) / 2.0) // gridsize)
    n_row = int(((y1 + y2) / 2.0) // gridsize)

    # clamp indices
    n_row = max(0, min(n_row, transform.shape[0] - 1))
    n_col = max(0, min(n_col, transform.shape[1] - 1))

    # Retrieve original top-left offset for the grid cell
    o_x, o_y = transform[n_row][n_col]

    # Calculate the absolute coordinates in the original image
    abs_x1 = x1 - (n_col * gridsize) + o_x
    abs_y1 = y1 - (n_row * gridsize) + o_y
    abs_x2 = x2 - (n_col * gridsize) + o_x
    abs_y2 = y2 - (n_row * gridsize) + o_y

    return abs_x1, abs_y1, abs_x2, abs_y2


@register_jit()
def _unpack_grid_bboxes_conf_classid(
    detections: list[tuple[tuple[int, int, int, int], float, int]],
    transform: np.ndarray,
    gridsize: int,
) -> list[tuple[tuple[int, int, int, int], float, int]]:
    unpacked_dets: list[tuple[tuple[int, int, int, int], float, int]] = []
    for bbox, conf, classid in detections:
        abs_x1, abs_y1, abs_x2, abs_y2 = _unpack_grid_single_bbox(
            bbox,
            transform,
            gridsize,
        )

        # Append the unpacked detection
        unpacked_dets.append(((abs_x1, abs_y1, abs_x2, abs_y2), conf, classid))
    return unpacked_dets


@register_jit()
def _unpack_grid_bboxes(
    detections: list[tuple[int, int, int, int]],
    transform: np.ndarray,
    gridsize: int,
) -> list[tuple[int, int, int, int]]:
    unpacked_dets: list[tuple[int, int, int, int]] = []
    for bbox in detections:
        abs_x1, abs_y1, abs_x2, abs_y2 = _unpack_grid_single_bbox(
            bbox,
            transform,
            gridsize,
        )

        # Append the unpacked detection
        unpacked_dets.append((abs_x1, abs_y1, abs_x2, abs_y2))
    return unpacked_dets


@register_jit()
def _simple_grid_repack(
    image: np.ndarray,
    cells: list[tuple[tuple[int, int, int, int], tuple[int, int]]],
    gridsize: int,
) -> tuple[np.ndarray, np.ndarray]:
    # need to repack the cells into a new image
    num_cells = len(cells)
    dim1 = max(1, math.ceil(math.sqrt(num_cells)))
    dim2 = max(1, math.ceil(num_cells / dim1))

    # allocate new data for the patches
    new_image: np.ndarray = np.zeros(
        (dim2 * gridsize, dim1 * gridsize, 3),
        dtype=np.uint8,
    )

    # copy the old data into new packed image
    # generate the transforms
    # new_grids: np.ndarray = np.zeros((self._n_rows, self._n_cols, 2), dtype=int)
    new_grids: np.ndarray = np.zeros((dim2, dim1, 2), dtype=int)
    for i, (bbox, _) in enumerate(cells):
        x1, y1, x2, y2 = bbox

        # generate the new row/col
        n_row = math.floor(i / dim1)  # Fixed dimension calculation
        n_col = i % dim1

        # generate the new bounding box
        n_x1 = n_col * gridsize
        n_x2 = n_x1 + gridsize
        n_y1 = n_row * gridsize
        n_y2 = n_y1 + gridsize

        # generate the offset, same as old coords for x1, y1
        offset = (x1, y1)

        # perform the data copy
        new_image[n_y1:n_y2, n_x1:n_x2] = image[y1:y2, x1:x2]

        # save the new grid entry
        new_grids[n_row, n_col] = offset

    return new_image, new_grids


@register_jit()
def _connected_components_grid_repack(
    image: np.ndarray,
    cells: list[tuple[tuple[int, int, int, int], tuple[int, int]]],
    gridsize: int,
) -> tuple[np.ndarray, np.ndarray]:
    # identify connected components
    matched: set[tuple[int, int]] = set()
    groups: list[
        tuple[
            list[tuple[int, int, int, int]],
            list[tuple[int, int]],
        ],
    ] = []
    for idx1, (cell1, loc1) in enumerate(cells):
        if loc1 in matched:
            continue

        group_hash: set[tuple[int, int]] = set()
        group_locs: list[tuple[int, int]] = [loc1]
        group_boxes: list[tuple[int, int, int, int]] = [cell1]
        matched.add(loc1)
        group_hash.add(loc1)

        for idx2, (cell2, loc2) in enumerate(cells):
            if idx1 == idx2:
                continue

            if loc2 in matched:
                continue

            # if not same cell and not matched already see if we can find a match
            # check if the cells are adjacent (non-diagonal)
            potentials = [
                (loc2[0] - 1, loc2[1]),
                # (loc2[0] + 1, loc2[1]),
                (loc2[0], loc2[1] - 1),
                # (loc2[0], loc2[1] + 1),
            ]
            for ploc in potentials:
                if ploc in group_hash:
                    group_locs.append(loc2)
                    group_boxes.append(cell2)
                    matched.add(loc2)
                    group_hash.add(loc2)
                    break

        groups.append((group_boxes, group_locs))

    print(f"Groups: {len(groups)}, Boxes: {len(cells)}")
    # need to debug view this
    import cv2
    from cv2ext.bboxes._bounding import bounding
    from cv2ext.image.draw import rectangle
    new_image = np.zeros(image.shape, dtype=np.uint8)
    for group in groups:
        for bbox in group[0]:
            x1, y1, x2, y2 = bbox
            new_image[y1:y2, x1:x2] = image[y1:y2, x1:x2]
        o_bbox = bounding(group[0])
        rectangle(new_image, o_bbox)

    # First, for each group, compute its bounding rectangle in grid-cell coordinates.
    # Assume that each cells loc is a tuple (col, row) (i.e. (x, y)).
    groups_info = []  # each element: (group_boxes, group_locs, min_x, min_y, group_width, group_height)
    total_cells = 0
    for boxes, locs in groups:
        cols = [loc[0] for loc in locs]
        rows = [loc[1] for loc in locs]
        min_x = min(cols)
        max_x = max(cols)
        min_y = min(rows)
        max_y = max(rows)
        group_width = max_x - min_x + 1  # in number of grid cells
        group_height = max_y - min_y + 1
        total_cells += group_width * group_height
        groups_info.append((boxes, locs, min_x, min_y, group_width, group_height))

    # Estimate a target width (in grid cells) roughly equal to the square root of total cells.
    target_cols = max(1, math.ceil(math.sqrt(total_cells)))

    # Pack groups in “shelves”
    placements = []  # will hold for each group a tuple (offset_x, offset_y) in grid cells
    current_x = 0
    current_y = 0
    shelf_height = 0
    max_used_cols = 0
    for info in groups_info:
        _, _, _, _, group_width, group_height = info
        # If this group doesn't fit in the current shelf, start a new shelf.
        if current_x + group_width > target_cols:
            current_y += shelf_height
            current_x = 0
            shelf_height = 0
        placements.append((current_x, current_y))
        current_x += group_width
        shelf_height = max(shelf_height, group_height)
        max_used_cols = max(max_used_cols, current_x)
    total_grid_rows = current_y + shelf_height
    total_grid_cols = max_used_cols

    # Allocate new image and a new grid array to store original offsets.
    img_h = max(gridsize, total_grid_rows * gridsize)
    img_w = max(gridsize, total_grid_cols * gridsize)
    # new_image = np.zeros(
    #     (img_h, img_w, 3),
    #     dtype=np.uint8,
    # )
    # new_grids: each cell in the new grid holds the original offset (top-left of the bounding box)
    new_grids = np.zeros((total_grid_rows, total_grid_cols, 2), dtype=int)

    # # Initialize new_grids with a sentinel value (-1,-1) to denote an empty cell.
    # new_grids.fill(-1)

    # # For each group, copy each cell from the original image into the new image.
    # # We preserve the relative arrangement within the group.
    # for (boxes, locs, min_x, min_y, _, _), (
    #     placement_x,
    #     placement_y,
    # ) in zip(groups_info, placements):
    #     # For each cell in this group, determine its new grid coordinates relative to the groups placement.
    #     # Note: the original loc of the cell is in grid coordinates; subtract the min to get a 0-based index.
    #     for bbox, loc in zip(boxes, locs):
    #         # relative position inside the group:
    #         rel_x = loc[0] - min_x
    #         rel_y = loc[1] - min_y
    #         new_col = placement_x + rel_x
    #         new_row = placement_y + rel_y

    #         # Compute new pixel coordinates
    #         n_x1 = new_col * gridsize
    #         n_y1 = new_row * gridsize
    #         n_x2 = n_x1 + gridsize
    #         n_y2 = n_y1 + gridsize

    #         x1, y1, x2, y2 = bbox
    #         # Copy the patch from the original image into the new location.
    #         new_image[n_y1:n_y2, n_x1:n_x2] = image[y1:y2, x1:x2]

    #         # Save the original offset (here, we use the top-left coordinate of the bbox)
    #         new_grids[new_row, new_col] = (x1, y1)

    return new_image, new_grids


class AbstractGridFramePacker(AbstractFramePacker):
    """Pack regions of a frame together based on a grid."""

    def __init__(
        self: Self,
        image_shape: tuple[int, int],
        gridsize: int = 128,
        detection_buffer: int = 30,
    ) -> None:
        """
        Create a new GridFramePacker.

        Parameters
        ----------
        image_shape : tuple[int, int]
            The shape of the image in form (width, height).
        gridsize : int, optional
            The size of each cell in the overlaid grid.
            Default is 128.
        detection_buffer : int, optional
            The number of frames to consider for detection activity.
            Used instead of current frame count once frame count exceeds buffer size.
            Allows more recent detections to have more influence.
            Default is 30.

        """
        super().__init__()
        self._width, self._height = image_shape
        self._gridsize = gridsize
        self._detection_buffer = detection_buffer

        # assign type hints to variables used in initialize_cells
        self._n_cols: int
        self._n_rows: int
        self._col_step: int
        self._row_step: int
        self._num_dets: np.ndarray
        self._cells: np.ndarray

        self._initialize_cells()

        # tracking variables
        self._counter: int = 0

    def reset(self: Self, image_shape: tuple[int, int] | None = None) -> None:
        """
        Reset the packer.

        Parameters
        ----------
        image_shape : tuple[int, int] | None
            The shape of the image in form (height, width).

        """
        if image_shape:
            self._height, self._width = image_shape
        self._initialize_cells()
        self._counter = 0

    def _initialize_cells(self: Self) -> None:
        """Initialize the grid cells and related parameters."""
        # num rows/cols
        self._n_cols = math.ceil(self._width / self._gridsize)
        self._n_rows = math.ceil(self._height / self._gridsize)

        # step size between grid cells
        self._col_step = (
            int((self._width - self._gridsize) / (self._n_cols - 1))
            if self._n_cols > 1
            else self._width
        )
        self._row_step = (
            int((self._height - self._gridsize) / (self._n_rows - 1))
            if self._n_rows > 1
            else self._height
        )

        # detection count info
        self._num_dets = np.zeros((self._n_rows, self._n_cols), dtype=int)

        # create the cell setup
        self._cells = np.zeros((self._n_rows * self._n_cols, 6), dtype=int)
        index: int = 0
        for i in range(self._n_rows):
            for j in range(self._n_cols):
                v_off = i * self._row_step
                h_off = j * self._col_step
                bbox = (
                    h_off,
                    v_off,
                    h_off + self._gridsize,
                    v_off + self._gridsize,
                )
                self._cells[index, :4] = bbox
                self._cells[index, 4:] = (i, j)
                index += 1

    @abstractmethod
    def _should_explore(
        self: Self,
        image: np.ndarray,
        bbox: tuple[int, int, int, int],
        row: int,
        col: int,
        detections: int,
    ) -> bool:
        """
        Whether to explore a grid cell based on detection activity.

        Parameters
        ----------
        image : np.ndarray
            The image to be packed.
        bbox : tuple[int, int, int, int]
            The bounding box of the cell.
        row : int
            The row of the cell.
        col : int
            The column of the cell.
        detections : int
            The number of detections in the cell.

        Returns
        -------
        bool
            Whether to explore the cell.

        """

    def pack(
        self,
        image: np.ndarray,
        exclude: tuple[int, int, int, int]
        | list[tuple[int, int, int, int]]
        | None = None,
        method: str = "smart",
    ) -> tuple[np.ndarray, np.ndarray]:
        """
        Pack regions of a frame together.

        Parameters
        ----------
        image : np.ndarray
            The image to pack.
        exclude : tuple[int, int, int, int] | list[tuple[int, int, int, int]], optional
            Regions of the image to exclude from the packing.
            By default None.
        method : str, optional
            The method to pack the bounding boxes with.
            Options are: ['simple', 'smart']
            Simple will place tiles of the grid FCFS basis in the new image,
            while smart will attempt to place connected regions together.

        Returns
        -------
        tuple[np.ndarray, np.ndarray]
            The packed image and the transform information.

        Raises
        ------
        ValueError
            If the image shape does not match the packer shape.

        """
        height, width = image.shape[:2]
        if height != self._height or width != self._width:
            err_msg = f"Image shape {image.shape} does not match packer shape {self._height, self._width}."
            raise ValueError(err_msg)

        # get the excluded cells
        excluded_cells: set[tuple[int, int]] = set()
        if exclude is not None and len(exclude) > 0:
            if isinstance(exclude, tuple):
                excluded_cells = set(
                    _bbox_to_gridcells(
                        exclude,
                        self._row_step,
                        self._col_step,
                        self._n_rows,
                        self._n_cols,
                    ),
                )
            else:
                excluded_cells = _bboxes_to_gridcells(
                    exclude,
                    self._row_step,
                    self._col_step,
                    self._n_rows,
                    self._n_cols,
                )

        # get all cells which are not in the excluded region
        included_cells = [
            (x1, y1, x2, y2, r, c)
            for (x1, y1, x2, y2, r, c) in self._cells
            if (r, c) not in excluded_cells
        ]

        # need to assess if the cells should be included based on detections and NCC
        filtered_cells: list[tuple[tuple[int, int, int, int], tuple[int, int]]] = []
        for x1, y1, x2, y2, row, col in included_cells:
            bbox = (x1, y1, x2, y2)
            if self._should_explore(
                image,
                bbox,
                row,
                col,
                self._num_dets[row][col],
            ):
                filtered_cells.append((bbox, (row, col)))

        # use the simple grid repacking
        if method == "simple":
            new_image, new_grids = _simple_grid_repack(
                image,
                filtered_cells,
                self._gridsize,
            )
        else:
            new_image, new_grids = _connected_components_grid_repack(
                image,
                filtered_cells,
                self._gridsize,
            )

        # update the image
        self._prev_image = image
        self._counter += 1

        return new_image, new_grids

    def unpack(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
        transform: np.ndarray,
    ) -> (
        list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]]
    ):
        """
        Unpack regions of a frame.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The regions to unpack.
        transform : np.ndarray
            The transform information generated by the pack method.

        Returns
        -------
        list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]

        """
        if len(detections) == 0:
            return []

        # get the type of detections passed
        if len(detections[0]) == 3:
            return _unpack_grid_bboxes_conf_classid(
                detections,  # type: ignore[arg-type]
                transform,
                self._gridsize,
            )

        return _unpack_grid_bboxes(detections, transform, self._gridsize)  # type: ignore[arg-type]

    def update(
        self: Self,
        detections: list[tuple[int, int, int, int]]
        | list[tuple[tuple[int, int, int, int], float, int]],
    ) -> None:
        """
        Update the packer with new detections.

        Parameters
        ----------
        detections : list[tuple[int, int, int, int]] | list[tuple[tuple[int, int, int, int], float, int]]
            The detections to update the packer with.

        """
        # add det counts to all possible grids with detections
        for elements in detections:
            if len(elements) == 3:
                bbox, _, _ = elements
            else:
                bbox = elements

            # get the grid cells that the bbox intersects
            grids = _bbox_to_gridcells(
                bbox,
                self._row_step,
                self._col_step,
                self._n_rows,
                self._n_cols,
            )

            # increment the detection count for each grid cell
            for o_row, o_col in grids:
                if 0 <= o_row < self._n_rows and 0 <= o_col < self._n_cols:
                    self._num_dets[o_row][o_col] += 1

        # decrement all counters by 1
        self._num_dets = np.maximum(0, self._num_dets - 1)


class AnnealingFramePacker(AbstractGridFramePacker):
    """
    Pack regions of a frame together based on detection activity.

    Detections are represented as a list of bounding boxes with
    scores and class id labels optional.
    """

    def __init__(
        self: Self,
        image_shape: tuple[int, int],
        gridsize: int = 128,
        alpha: float = 0.01,
        min_prob: float = 0.1,
        detection_buffer: int = 30,
    ) -> None:
        """
        Create a new AnnealingFramePacker.

        Parameters
        ----------
        image_shape : tuple[int, int]
            The shape of the image in form (width, height).
        gridsize : int, optional
            The size of each cell in the overlaid grid.
            Default is 128.
        alpha : float, optional
            The learning rate for the annealing process.
            Default is 0.01.
        min_prob : float, optional
            The minimum probability for a region to be considered active.
            Default is 0.1.
        detection_buffer : int, optional
            The number of frames to consider for detection activity.
            Used instead of current frame count once frame count exceeds buffer size.
            Allows more recent detections to have more influence.
            Default is 30.

        """
        super().__init__(image_shape, gridsize, detection_buffer)

        # specific annealing parameters
        self._alpha = alpha
        self._min_prob = min_prob

    def _should_explore(
        self: Self,
        image: np.ndarray,  # noqa: ARG002
        bbox: tuple[int, int, int, int],  # noqa: ARG002
        row: int,  # noqa: ARG002
        col: int,  # noqa: ARG002
        detections: int,
    ) -> bool:
        time_factor = math.exp(-self._alpha * self._counter)
        detection_factor = min(
            1.0,
            detections / (min(self._counter, self._detection_buffer - 1) + 1),
        )
        explore_probability = max(self._min_prob, time_factor + detection_factor)
        return random.random() < explore_probability


class RandomFramePacker(AbstractGridFramePacker):
    """Pack regions of a frame together randomly."""

    def __init__(
        self: Self,
        image_shape: tuple[int, int],
        gridsize: int = 128,
        threshold: float = 0.1,
        detection_buffer: int = 30,
    ) -> None:
        """
        Create a new RandomFramePacker.

        Parameters
        ----------
        image_shape : tuple[int, int]
            The shape of the image in form (width, height).
        gridsize : int, optional
            The size of each cell in the overlaid grid.
            Default is 128.
        threshold : float, optional
            The threshold for which to randomly explore a grid cell.
            If the random value is less than the threshold, the cell is explored.
            Threshold of 0.1 means 10% of the time a cell is explored.
            Default is 0.1.
        detection_buffer : int, optional
            The number of frames to consider for detection activity.
            Used instead of current frame count once frame count exceeds buffer size.
            Allows more recent detections to have more influence.
            Default is 30.

        """
        super().__init__(image_shape, gridsize, detection_buffer)

        # specific parameters
        self._threshold = threshold

    def _should_explore(
        self: Self,
        image: np.ndarray,  # noqa: ARG002
        bbox: tuple[int, int, int, int],  # noqa: ARG002
        row: int,  # noqa: ARG002
        col: int,  # noqa: ARG002
        detections: int,  # noqa: ARG002
    ) -> bool:
        return random.random() < self._threshold
